{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2d4121-4c70-4014-8ada-59910df0a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 1. Loading the weights file\n",
    "weight_file_path = \"../param/Net_Quant/Net_Quant_lr0.0008_n_steps200_3000best_loss.pth.tar\"\n",
    "loaded_weights = torch.load(weight_file_path)\n",
    "\n",
    "dest_path = \"../param/Net_Quant/Net_Quant_modify.pth.tar\"\n",
    "\n",
    "group = 9\n",
    "# 2. Get the weights for a specific layer\n",
    "N = 10\n",
    "# init_feature is the name of the part to be processed\n",
    "for x in range(N):\n",
    "    # N denotes the number of layers of init_feature\n",
    "    desired_layer_name = f\"init_feature.{x}.conv.weight\"\n",
    "    if desired_layer_name in loaded_weights['state_dict']:\n",
    "        # Extracting weights\n",
    "        weights_to_modify = loaded_weights['state_dict'][desired_layer_name]\n",
    "        OFM, IFM_group, k_h, k_w = weights_to_modify.shape\n",
    "        # Initialize the sparse matrix\n",
    "        W_sparse = torch.zeros((OFM, IFM_group * group, k_h, k_w), dtype=torch.float)\n",
    "        num = IFM_group\n",
    "        # Set up the sparse weight matrix\n",
    "        for i in range(OFM):\n",
    "            OFM_group = OFM // group\n",
    "            n = i // OFM_group\n",
    "            in_start = n * num\n",
    "            in_end = (n + 1) * num\n",
    "            W_sparse[i, in_start:in_end, :, :] = weights_to_modify[i, :, :, :]\n",
    "        loaded_weights['state_dict'][desired_layer_name] = W_sparse\n",
    "torch.save(loaded_weights, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03272195-4eb4-43a3-86e7-44a854223aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have\n"
     ]
    }
   ],
   "source": [
    "weight_file_path = dest_path\n",
    "loaded_weights = torch.load(weight_file_path)\n",
    "\n",
    "desired_layer_name = f\"BuildCost.weight\"\n",
    "if desired_layer_name in loaded_weights['state_dict']:\n",
    "    print('have')\n",
    "    # Extracting weights\n",
    "    weights_to_modify = loaded_weights['state_dict'][desired_layer_name]\n",
    "    OFM, IFM_group, k_h, k_w = weights_to_modify.shape\n",
    "    # Initialize the sparse matrix\n",
    "    W_sparse = torch.zeros((OFM, IFM_group * group, k_h, k_w), dtype=torch.float)\n",
    "    num = IFM_group\n",
    "    # Set up the sparse weight matrix\n",
    "    for i in range(OFM):\n",
    "        OFM_group = OFM // group\n",
    "        n = i // OFM_group\n",
    "        in_start = n * num\n",
    "        in_end = (n + 1) * num\n",
    "        W_sparse[i, in_start:in_end, :, :] = weights_to_modify[i, :, :, :]\n",
    "    loaded_weights['state_dict'][desired_layer_name] = W_sparse\n",
    "torch.save(loaded_weights, weight_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
